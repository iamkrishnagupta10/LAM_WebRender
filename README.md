# LAM\_WebRender ðŸŽ¨

**Lightweight WebGL Renderer** - Real-time 3D Gaussian Splatting Render Engine for LAM and LAM\_Audio2Expression.

Our rendering engine is now available as an [NPM package](https://www.npmjs.com/package/gaussian-splat-renderer-for-lam).

---

## ðŸš€ Getting Started

1. Install dependencies

   ```bash
   npm install
   ```
2. Run development server

   ```bash
   npm run dev
   ```
3. Open in browser

<pre class="blog-pre"><div class="code-copy"><span></span><div><div class="code-copy-btn"><i class="next-icon next-icon-copy next-large"></i></div></div></div><code class="blog-code">http://localhost:5173/
</code></pre>

---

## ðŸ“¦ Core Features

âœ¨ **Key Highlights**

* Real-time rendering support: Interactive LAM avatars with LAM\_Audio2Expression facial animations
* NPM package integration: Use with `npm install gaussian-splat-renderer-for-lam`

## ðŸ“¦ NPM Package Usage

### Installation

```bash
npm install gaussian-splat-renderer-for-lam
```

### Basic Usage Example

```javascript
    import * as GaussianSplats3D from 'gaussian-splat-renderer-for-lam';
    const div = document.getElementById('GaussianRenderer');
    const assetPath = './asset/arkit/p2-1.zip'; //the real asset address
    const render = await GaussianSplats3D.GaussianSplatRenderer.getInstance(div, assetPath);

```

> ðŸ’¡ **Advanced Features**
>
> * Facial animations: Load `/asset/test_expression_1s.json` for expression control
> * Custom avatars: Generate new models via [LAM](https://github.com/aigc3d/LAM.git) and replace ZIP files

---

## ðŸ”— Related Projects

copy


| Feature               | Repository                                                                    |
| --------------------- | ----------------------------------------------------------------------------- |
| Chat integration      | [OpenAvatarChat](https://github.com/HumanAIGC-Engineering/OpenAvatarChat.git) |
| Avatar generation     | [LAM](https://github.com/aigc3d/LAM.git)                                      |
| Expression generation | [LAM\_Audio2Expression](https://github.com/aigc3d/LAM_Audio2Expression.git)   |


---
## ðŸ“º Demo


**The demo shows that [LAM\_Audio2Expression](https://github.com/aigc3d/LAM_Audio2Expression.git) leverages audio input to generate ARKit blendshapes-driven facial expressions, powering ultra-realistic 3D avatars generated by [LAM](https://github.com/aigc3d/LAM),  and rendered with this render engine.**


<div align="center">
  <video controls src="https://github.com/user-attachments/assets/2bb4e74f-cd96-4c50-9833-fae10b1ead4c
">
  </video>
</div>



---

**The demo highlights a **low-latency SDK** for real-time interactive chat avatars, developed using the same rendering engine as the core framework.**

<div align="center">
  <video controls src="https://github.com/user-attachments/assets/98f66655-e1c1-40a9-ab58-bdd49dafedda" width="80%">
  </video>
</div>

## ðŸ§ª Example Files

* Avatar model: `./asset/arkit/p2-1.zip`
* Expression data: `./asset/test_expression_1s.json`

---

## ðŸ“œ License

This project is licensed under the MIT License.
